\documentclass[solution,addpoints,12pt]{exam}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

\newenvironment{Solution}{\begin{EnvFullwidth}\begin{solution}}{\end{solution}\end{EnvFullwidth}}

\printanswers
%\unframedsolutions
\pagestyle{headandfoot}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%% INSTRUCTIONS %%%%%%%%%%%%%%%%%%%%%
% * Fill in your name and roll number below

% * Answer in place (after each question)

% * Use \begin{solution} and \end{solution} to typeset
%   your answers.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Fill in the details below
\def\studentName{\textbf{TODO: Name}}
\def\studentRoll{\textbf{TODO: Roll}}

\firstpageheader{Approximation Algorithms: Assignment 2}{}{\studentName, \studentRoll}
\firstpageheadrule

\newcommand{\brac}[1]{\left[ #1 \right]}
\newcommand{\curly}[1]{\left\{ #1 \right\}}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\card}[1]{\left\lvert #1 \right\rvert}

\newcommand{\prob}{\operatorname{\mathbf{Pr}}}
\newcommand{\ex}{\operatorname{\mathbf{E}}}
\newcommand{\from}{\leftarrow}

\newcommand{\field}{\mathbb{F}}
\newcommand{\reals}{\mathbb{R}}
\renewcommand{\mod}{\operatorname{mod}}
\newcommand{\hashFamily}{\mathcal{H}}

\newcommand{\Yes}{\texttt{Yes}}
\newcommand{\No}{\texttt{No}}

\begin{document}

\begin{questions}


\question[15] \textbf{Routing many pairs at once}  We will complete the missing details from the class for routing many demands at once. Recall that our approach was to formulate an LP for this problem, and perform randomized rounding. The problem is as follows: given a graph (undirected and unweighted) $G  = (V,E)$, and a collection of pairs $\{(s_1, t_1), (s_2, t_2), \ldots (s_k, t_k)\}$ where each source $s_i \in V$ and terminal $t_i \in V$, suppose I promise you that there exist paths $P^*_i$ from $s_i$ to $t_i$ which are all disjoint. This means that we can route the unit demand from $s_i$ to $t_i$ with the maximum edge load of $1$.
The question we ask is,  can we efficiently find a collection of paths $P_i$ from $s_i$ to $t_i$ such that the maximum load on any edge is at most $O(\log n)$. 

The LP we formulated in class is as follows: in the following, we let ${\cal P}_i$ denote the set of all simple paths between $s_i$ and $t_i$.

\begin{align*}
\sum_{P \in {\cal P}_i} f_p & = 1  \, \qquad \forall \, i \in \{1, 2, \ldots, k\} \\
\sum_{i} \sum_{P \in {\cal P}_i: e \in P} f_p & \leq 1  \, \qquad \forall \, e \in E
\end{align*}


\begin{parts}
	\part[3] Explain why this LP is feasible if the promise holds.
	
	\begin{solution}
		\begin{proof}
			$1 + 1 = 2$.
		\end{proof}
	\end{solution}
	
	\part[4] Now, this LP has exponentially many variables, and so we cannot find a feasible solution in the present form in polynomial time. So let us come up with a potentially simpler formulation of the same LP. In this, we have the following variables: first, we replace each edge $e$ by two directed edges $(u,v)$ and $(v,u)$. The former supports flows going from $u$ to $v$, and the latter supports flow from $v$ to $u$. Henceforth, we denote each directed edge as an \emph{arc}. Let $A$ denote the set of all arcs in the graph (so $|A| = 2 |E|$). Then, for an arc $a = (u,v)$, let $x_a^i$ denote the amount of flow arc $a$ carries for the demand $s_i$-$t_i$.
	
	\begin{align*}
	\sum_{v: (s_i, v) \in A} x_{(s_i,v)}^i & = 1  \, \qquad & \forall \, i \in \{1, 2, \ldots, k\} \\
	\sum_{v: (v, t_i) \in A} x_{(v,t_i)}^i & = 1  \, \qquad  & \forall \, i \in \{1, 2, \ldots, k\} \\
	\sum_{v: (u, v) \in A} x_{(u,v)}^i & = \sum_{v: (v, u) \in A} x_{(v,u)}^i  \, \qquad & \forall  \, i \in \{1, 2, \ldots, k\}, \forall u \in V \setminus \{s_i, t_i\} \\
	\sum_{i} x_{(u,v)}^i +  \sum_{i} x_{(v,u)}^i & \leq 1  \, \qquad & \forall \, e = (u,v) \in E
	\end{align*}
	
	Essentially, it is trying to capture how the flow of each source-terminal splits and joins through the edges of the graph. The nice feature is that the new  LP is much smaller, and has size only polynomial in $n, m$. Show that if the original promise holds, then the new LP is also feasible.
	
	\begin{solution}
		\begin{proof}
$1 + 1 = 2$.
		\end{proof}
	\end{solution}
	
	\part[8] Show that we can find a feasible solution to the first LP using a feasible solution to the second LP.
	\begin{solution}
		\begin{proof}
			$1 + 1 = 2$.
		\end{proof}
	\end{solution}
\end{parts}


\question[15] \textbf{(Sending jobs to machines.)}  Here we get a better understanding of using Chernoff + union bound together. Suppose there are $m$ jobs, and $m$ machines. If we assign each job to a uniformly random machine (and these decisions are independent), we try to see how unbalanced the machine loads can be.
\begin{parts}
	\part[1] What is the expected load of any machine, i.e., number of jobs assigned to it?
	
	\begin{solution}
		\begin{proof}
			$1 + 1 = 2$.
		\end{proof}
	\end{solution}
	
	\part[2] What is the expected number of empty machines, i.e., ones where there are no jobs assigned?
	\begin{solution}
		\begin{proof}
			$1 + 1 = 2$.
		\end{proof}
	\end{solution}
	
	\part[3] Use Chernoff bounds to show that, for any fixed machine $i$, the probability that its load exceeds $c \cdot \log m$ is smaller than $1/m^3$, for some constant $c$. You can use your favorite form of Chernoff bound (either taught in class or you find online. But make sure you write down the exact bound you are using).
	\begin{solution}
		\begin{proof}
			$1 + 1 = 2$.
		\end{proof}
		\end{solution}
	
	\part[1] If we use the union bound along with the previous part, what is the success probability of \emph{all machines} having load at most $c \cdot \log m$, i.e., the maximum load is bounded?
	\begin{solution}
		\begin{proof}
			$1 + 1 = 2$.
		\end{proof}
	\end{solution}
	
		\part[2] Now if the number of jobs is much more than $m$, i.e., $n >> m$, what is the expected load of any machine?
	\begin{solution}
		\begin{proof}
			$1 + 1 = 2$.
		\end{proof}
	\end{solution}
	
			\part[6] Using Chernoff bounds and union bound,  can you show that with high  probability, all machines will have load at most $\frac{n}{m} + O(1) \sqrt{\frac{n \log m}{m}}$? 
	\begin{solution}
		\begin{proof}
			$1 + 1 = 2$.
		\end{proof}
	\end{solution}
	
	
\end{parts}



\question[15] \textbf{(Designing a Tournament)}  This question will help you understand the applications of Chernoff bound and Union bound more, as you'll deal with tuning parameters to optimize the efficiency of the system. You'll also get an understanding of why NBA tournaments are designed the way they are, with more repeated matches being played as we get closer to the finals. For example, in the NBA, the early rounds are \emph{best-of-five}, and the later rounds become \emph{best-of-seven}. You will understand why, and also learn how to design tournaments with $n$ participants, for large $n$.

Suppose there are $n$ teams, and they are totally ranked. That is, there is a well-defined best team, second ranked team and so on. It's just that we (the tournament designer) don't know the ranking. Moreover, assume that for any given match between two players, the better ranked team will win the match with probability $p = 0.6$, \emph{independent of all other matches between these players and all other players also}. 

\begin{parts}
\part[3] Let $n$ be a power of two, and fix an \emph{arbitrary tournament tree} starting with $n/2$ matches, then $n/4$ matches and so on. That is, initially, team 1 plays team 2, team 3 plays team 4, and so on (each series is only $1$ game). The winners advance, and pair up and play each other once, and so on until one team remains. What is the probability that the best team wins the tournament?

  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}

\part[4] Now change the tournament to make each series as a \emph{best-of-$k$} series. Using Chernoff + union bound, show that if $k = c \cdot \log \log n$ for some constant $c$, then the best team winning the overall tournament with some constant probability, say $0.9$? So how many games have we conducted overall?
  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}

\part[8] Can you get better dependence on $n$ if you allow different number of games in each round: example, try having $k_1$ games in the first series, $k_2$ games in the next series, etc. and optimize for these values to get a total of $O(n)$ games which still retains $0.9$ probability of the best team winning eventually. 
  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}
\end{parts}



\question[0] {\bf Difficulty Level.} How difficult was this homework? How much time would you have spent on these questions?
  \begin{solution}
  \begin{proof}
  $1 + 1 = 2$.
  \end{proof}
  \end{solution}



\end{questions}
\end{document} 